{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records = pd.read_csv('../dengue_features_train.csv')\n",
    "testing_records = pd.read_csv('../dengue_features_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_records.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records.groupby('city').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_records.groupby('city').mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like data for the two cities are very different but the trends remain across the test and train datasets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records_sj = training_records[training_records['city'] == 'sj'].drop('city', 1)\n",
    "training_records_iq = training_records[training_records['city'] == 'iq'].drop('city', 1)\n",
    "testing_records_sj = testing_records[testing_records['city'] == 'sj'].drop('city', 1)\n",
    "testing_records_iq = testing_records[testing_records['city'] == 'iq'].drop('city', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records_iq.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_records_iq.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_records_sj.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_records_sj.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like train dataset and the test dataset can be combined for the purpose of smoothing, outlier finding etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(training_records_iq), len(testing_records_iq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(len(training_records_sj), len(testing_records_sj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq = pd.concat([training_records_iq, testing_records_iq], ignore_index=True)\n",
    "records_sj = pd.concat([training_records_sj, testing_records_sj], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(records_iq.drop(['year', 'weekofyear'], axis=1)\n",
    "    .plot(kind='kde', subplots=True, figsize=(14, 30), layout=(10, 2), sharex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(records_sj.drop(['year', 'weekofyear'], axis=1)\n",
    "    .plot(kind='kde', subplots=True, figsize=(14, 30), layout=(10, 2), sharex=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_iq = records_iq.corr()\n",
    "corr_sj = records_sj.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "corr_heatmap_iq = sns.heatmap(corr_iq)\n",
    "plt.title('Iquitos correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "corr_heatmap_sj = sns.heatmap(corr_sj)\n",
    "plt.title('San Juan correlations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select upper triangle of correlation matrix\n",
    "corr_upper_iq = corr_iq.where(np.triu(np.ones(corr_iq.shape), k=1).astype(np.bool))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop_iq = [column for column in corr_upper_iq.columns if any(corr_upper_iq[column] > 0.95) or any(corr_upper_iq[column] < -0.95)]\n",
    "to_drop_iq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_upper_sj = corr_sj.where(np.triu(np.ones(corr_sj.shape), k=1).astype(np.bool))\n",
    "to_drop_sj = [column for column in corr_upper_sj.columns if any(corr_upper_sj[column] > 0.95) or any(corr_upper_iq[column] < -0.95)]\n",
    "to_drop_sj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq.drop(to_drop_iq, axis=1, inplace=True)\n",
    "records_sj.drop(to_drop_sj, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't want to use same features twice, so we dropped columns more than 95% similar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq.drop(['year'], axis=1, inplace=True)\n",
    "records_sj.drop(['year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have `week_start_date`, so `year` and `weekofyear` are redundant. Wait! `weekofyear` can be thought to contain all unobserved seasonal variations. But `year` is too large to be a trend predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq[['reanalysis_air_temp_k', 'reanalysis_dew_point_temp_k', 'reanalysis_max_air_temp_k', \n",
    "            'reanalysis_min_air_temp_k']] -= 273.15\n",
    "records_sj[['reanalysis_air_temp_k', 'reanalysis_dew_point_temp_k', 'reanalysis_max_air_temp_k', \n",
    "            'reanalysis_min_air_temp_k']] -= 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert all Kelvins to Celsius."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "records_iq[['ndvi_ne', 'ndvi_nw', 'ndvi_se', 'ndvi_sw']].plot(figsize=(100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq['ndvi'] = records_iq[['ndvi_ne', 'ndvi_nw', 'ndvi_se', 'ndvi_sw']].mean(axis=1)\n",
    "records_iq.drop(['ndvi_ne', 'ndvi_nw', 'ndvi_se', 'ndvi_sw'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "records_sj[['ndvi_ne', 'ndvi_nw', 'ndvi_se', 'ndvi_sw']].plot(figsize=(100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_sj['ndvi_n'] = records_sj[['ndvi_ne', 'ndvi_nw']].mean(axis=1)\n",
    "records_sj['ndvi_s'] = records_sj[['ndvi_se', 'ndvi_sw']].mean(axis=1)\n",
    "records_sj.drop(['ndvi_ne', 'ndvi_nw', 'ndvi_se', 'ndvi_sw'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "records_iq[['reanalysis_air_temp_k', 'reanalysis_dew_point_temp_k', 'reanalysis_max_air_temp_k', \n",
    "            'reanalysis_min_air_temp_k']].plot(figsize=(100, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doesn't look like further reduceable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "records_sj[['reanalysis_air_temp_k', 'reanalysis_dew_point_temp_k', 'reanalysis_max_air_temp_k', \n",
    "            'reanalysis_min_air_temp_k']].plot(figsize=(100, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_sj['reanalysis_temp'] = records_sj[\n",
    "    ['reanalysis_air_temp_k', 'reanalysis_dew_point_temp_k', \n",
    "     'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k']].mean(axis=1)\n",
    "records_sj.drop(['reanalysis_air_temp_k', 'reanalysis_dew_point_temp_k', \n",
    "     'reanalysis_max_air_temp_k', 'reanalysis_min_air_temp_k'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "records_iq[['station_avg_temp_c', 'station_diur_temp_rng_c', \n",
    "                          'station_max_temp_c', 'station_min_temp_c']].plot(figsize=(50, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq[['station_avg_temp_c', 'station_diur_temp_rng_c', \n",
    "                          'station_max_temp_c', 'station_min_temp_c']].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variation of max, min and avg is quite similar while diur thing looks totally random. Avg looks very much like the average of max and min where when one of max or min is absent, avg is also absent. Hence we can go with min. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq.drop(['station_avg_temp_c', 'station_diur_temp_rng_c', \n",
    "                          'station_max_temp_c'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "records_sj[['station_avg_temp_c', 'station_diur_temp_rng_c', \n",
    "                          'station_max_temp_c', 'station_min_temp_c']].plot(figsize=(50, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_sj[['station_avg_temp_c', 'station_diur_temp_rng_c', \n",
    "                          'station_max_temp_c', 'station_min_temp_c']].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_sj.drop(['station_avg_temp_c', 'station_diur_temp_rng_c', \n",
    "                          'station_max_temp_c'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_sj.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_iq.to_csv('./generated/1-features-iq.csv', index=False)\n",
    "records_sj.to_csv('./generated/1-features-sj.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets = pd.read_csv('../dengue_labels_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets.drop(['year'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets['week_start_date'] = training_records['week_start_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets_sj = training_targets[training_targets['city'] == 'sj'].drop('city', 1)\n",
    "training_targets_iq = training_targets[training_targets['city'] == 'iq'].drop('city', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_targets_iq.to_csv('./generated/1-labels-train-iq.csv', index=False)\n",
    "training_targets_sj.to_csv('./generated/1-labels-train-sj.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mosquito life cycle: 8-10 days.\n",
    "https://www.cdc.gov/dengue/entomologyecology/m_lifecycle.html\n",
    "\n",
    "Incubation of dengue virus in human body can be upto 14 days. \n",
    "https://en.wikipedia.org/wiki/Dengue_fever\n",
    "\n",
    "Incubation inside mosquito: 8-12 days. \n",
    "https://www.cdc.gov/dengue/epidemiology/index.html\n",
    "\n",
    "Mosquito lives upto 4 weeks. \n",
    "\n",
    "It looks safe to take a 5 week window. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
