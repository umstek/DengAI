{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import IPython\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "\n",
    "print('Python version: %s.%s.%s' % sys.version_info[:3])\n",
    "print('IPython version:', IPython.__version__)\n",
    "print('numpy version:', np.__version__)\n",
    "print('pandas version:', pd.__version__)\n",
    "print('scikit-learn version:', sk.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_colwidth=-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "class EstimatorSelectionHelper:\n",
    "    def __init__(self, models, params):\n",
    "        if not set(models.keys()).issubset(set(params.keys())):\n",
    "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
    "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
    "        self.models = models\n",
    "        self.params = params\n",
    "        self.keys = models.keys()\n",
    "        self.grid_searches = {}\n",
    "    \n",
    "    def fit(self, X, y, cv=3, n_jobs=1, verbose=1, scoring=None, refit=False):\n",
    "        for key in self.keys:\n",
    "            print(\"Running GridSearchCV for %s.\" % key)\n",
    "            model = self.models[key]\n",
    "            params = self.params[key]\n",
    "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs, \n",
    "                              verbose=verbose, scoring=scoring, refit=refit, return_train_score=True)\n",
    "            gs.fit(X, y)\n",
    "            self.grid_searches[key] = gs    \n",
    "    \n",
    "    def score_summary(self, sort_by=None):\n",
    "        scores = pd.concat(list(map(lambda k: pd.DataFrame.from_dict({'estimator': k, **self.grid_searches[k].cv_results_}), self.keys)))\n",
    "        if sort_by: scores.sort_values(sort_by, inplace=True, ascending=False)\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_iq_train = pd.read_csv('./generated/dengue_features_train_s1_iq.csv')\n",
    "labels_iq_train = pd.read_csv('./generated/dengue_labels_train_iq.csv')\n",
    "features_sj_train = pd.read_csv('./generated/dengue_features_train_s1_sj.csv')\n",
    "labels_sj_train = pd.read_csv('./generated/dengue_labels_train_sj.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = preprocessing.scale(features_iq_train)\n",
    "y = labels_iq_train['total_cases']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "models2 = { \n",
    "    'GB_R': GradientBoostingRegressor(),\n",
    "#     'AB_R': AdaBoostRegressor(),\n",
    "#     'RF_R': RandomForestRegressor(),\n",
    "#     'MLP_R': MLPRegressor()\n",
    "}\n",
    "\n",
    "params2 = { \n",
    "    'GB_R': { 'learning_rate': np.logspace(-1.5, 0.5, 10), 'n_estimators': np.linspace(25, 75, endpoint=False, num=15).astype(int), 'min_samples_leaf': [6, 8, 10]},\n",
    "    'GB_R': { 'learning_rate': [0.1], 'n_estimators': [48], 'min_samples_leaf': [8], 'loss': ['ls'], 'criterion': ['mse']},\n",
    "    'AB_R': { 'learning_rate': np.logspace(-1.5, 0.5, 10), 'n_estimators': np.linspace(25, 75, endpoint=False, num=15).astype(int) },\n",
    "    'RF_R': { 'n_estimators': np.linspace(25, 75, endpoint=False, num=15).astype(int), 'min_samples_leaf': [6, 8, 10] },\n",
    "    'MLP_R': {}\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper2 = EstimatorSelectionHelper(models2, params2)\n",
    "helper2.fit(X, y, n_jobs=-1, scoring=['neg_mean_absolute_error', 'neg_mean_squared_error'], cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helper2.score_summary(sort_by='mean_test_neg_mean_absolute_error')[['estimator', 'mean_test_neg_mean_absolute_error', 'mean_test_neg_mean_squared_error', 'params']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Useless"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
